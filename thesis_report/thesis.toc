\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {english}{}\relax 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1}Introduction}{3}{section.1}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2}Literature Review}{4}{section.2}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.1}Adversarial examples}{4}{subsection.2.1}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.2}Adversarial training}{5}{subsection.2.2}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3}On-manifold vs Off-manifold Adversarial Robustness}{6}{subsection.2.3}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4}Self-supervised learning (SSL)}{7}{subsection.2.4}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.5}Shortcut Solutions and Feature Suppression in SSL}{11}{subsection.2.5}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.6}Robustness of contrastive learning}{12}{subsection.2.6}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.7}Robust Self-Supervised Training}{13}{subsection.2.7}%
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.7.1}Can contrastive learning avoid shortcut solutions?}{13}{subsubsection.2.7.1}%
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.7.2}Robust Pre-Training by Adversarial Contrastive Learning}{15}{subsubsection.2.7.2}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.8}SSL and Latent Variable Disentanglement}{16}{subsection.2.8}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3}Hypothesis}{17}{section.3}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4}Self-supervised learning, not robust on CIFAR10 }{18}{section.4}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.1}Models and training}{20}{subsection.4.1}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.2}Results for Standard Fine-tuning the Readout Layer}{21}{subsection.4.2}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.3}Results for Adversarial Fine-tuning the Readout Layer}{23}{subsection.4.3}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.4}CIFAR10 conclusion}{25}{subsection.4.4}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {5}Controlled datasets}{27}{section.5}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {6}Simple But Useful Toys}{28}{section.6}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {6.1}The triangle square dataset}{28}{subsection.6.1}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {6.2}The L-T dataset}{32}{subsection.6.2}%
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {6.2.1}Simplifying assumptions}{33}{subsubsection.6.2.1}%
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {6.2.2}Proof of model robustness}{34}{subsubsection.6.2.2}%
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {6.2.3}Observations from the Triangle-Square and L-T datasets}{37}{subsubsection.6.2.3}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {7}Knowing the causes is not enough ! (Causal3DIdent experiments)}{40}{section.7}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {7.1}Dataset creation}{40}{subsection.7.1}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {7.2}General idea}{41}{subsection.7.2}%
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {7.3}Experiments}{43}{subsection.7.3}%
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {8}Conclusion}{46}{section.8}%
